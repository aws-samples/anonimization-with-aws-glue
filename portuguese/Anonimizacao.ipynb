{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script python para anonimização de dados \n",
    "\n",
    "O objetivo deste script é ser importado como um job no Glue e então ser inserido no seu pipeline de dados para remoção de informações identificáveis (PII, PHI, etc).\n",
    "\n",
    "**Atenção/Disclaimer:** Este é um script de exemplo e deverá ser adaptado e testado de acordo com as necessidades da sua organização antes de estar pronto para entrar em produção.\n",
    "\n",
    "\n",
    "Para execução deste notebook em seu ambiente, escolha o kernel \"Sparkmagic (PySpark)\".\n",
    "\n",
    "Será necessário também executar o notebook a partir de um Glue Development Endpoint. Para mais informações: https://docs.aws.amazon.com/pt_br/glue/latest/dg/dev-endpoint.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "\n",
    "## @params: [JOB_NAME]\n",
    "args = {'JOB_NAME':'anonimizacao'}\n",
    "\n",
    "## Caminho de output para armazenamento do arquivo anonimizado no S3\n",
    "## TODO: substituir pelo caminho do seu bucket\n",
    "s3_output_path = \"s3://<<caminho onde o arquivo final será armazenado>>\"\n",
    "\n",
    "## Database do Glue Data Catalog com dados da Origem\n",
    "## TODO: substituir pelo seu database\n",
    "glue_database = \"<<seu database com os dados de origem no glue data catalog>>\"\n",
    "\n",
    "## Tabela do Glue Data Catalog com dados da Origem\n",
    "## TODO: substituir por sua tabela\n",
    "glue_table_name = \"<<sua tabela com os dados de origem no glue data catalog>>\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura do arquivo original\n",
    "\n",
    "Observe que \"database\" e \"table name\" são os nomes que foram criados no Glue Data Catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "job.init(args['JOB_NAME'], args)\n",
    "## @type: DataSource\n",
    "## @args: [database = glue_database, table_name = glue_table_name]\n",
    "## @return: datasource\n",
    "## @inputs: []\n",
    "datasource = glueContext.create_dynamic_frame.from_catalog(database = glue_database, table_name = glue_table_name)\n",
    "## @type: ApplyMapping\n",
    "## @args: [mapping = [(\"nome\", \"string\", \"nome\", \"string\"), (\"cpf\", \"string\", \"cpf\", \"string\"), (\"email\", \"string\", \"email\", \"string\"), (\"cep\", \"string\", \"cep\", \"string\"), (\"rua\", \"string\", \"rua\", \"string\"), (\"numero\", \"long\", \"numero\", \"long\"), (\"cidade\", \"string\", \"cidade\", \"string\"), (\"estado\", \"string\", \"estado\", \"string\"), (\"nascimento\", \"string\", \"nascimento\", \"string\"), (\"peso\", \"int\", \"peso\", \"int\")]]\n",
    "## @return: applymapping\n",
    "## @inputs: [frame = datasource]\n",
    "applymapping = ApplyMapping.apply(frame = datasource, mappings = [(\"nome\", \"string\", \"nome\", \"string\"), (\"cpf\", \"string\", \"cpf\", \"string\"), (\"email\", \"string\", \"email\", \"string\"), (\"cep\", \"string\", \"cep\", \"string\"), (\"rua\", \"string\", \"rua\", \"string\"), (\"numero\", \"long\", \"numero\", \"long\"), (\"cidade\", \"string\", \"cidade\", \"string\"), (\"estado\", \"string\", \"estado\", \"string\"), (\"nascimento\", \"string\", \"nascimento\", \"string\"), (\"peso\", \"long\", \"peso\", \"long\")])\n",
    "## @type: ResolveChoice\n",
    "## @args: [choice = \"make_struct\"]\n",
    "## @return: originalData\n",
    "## @inputs: [frame = applymapping]\n",
    "originalData = ResolveChoice.apply(frame = applymapping, choice = \"make_struct\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dado raw\n",
    "\n",
    "\n",
    "Para fins de visualização, vamos imprimir o dado raw, ou seja, na forma como ele chegou ao pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalData.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supressão\n",
    "\n",
    "Vamos aplicar agora supressão em alguns dados para exemplificar a técnica.\n",
    "Primeiramente, vamos suprimir os campos: \"rua\" e \"número\" da residência.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supressao = DropFields.apply(frame = originalData, \n",
    "                             paths=['rua', 'numero'])\n",
    "\n",
    "supressao.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalização\n",
    "\n",
    "Vamos aplicar agora generalização em alguns dados para exemplificar a técnica.\n",
    "\n",
    "Os campos generalizados são: \"nome\", \"email\", \"CEP\" e \"nascimento\".\n",
    "\n",
    "No exemplo abaixo, a função f = RecuperaUltimoSobrenome será aplicada ao DynamicFrame \"supressao\". O resultado será um novo DynamicFrame chamado \"nomeGeneralizado\" cuja coluna \"nome\" conterá apenas o sobrenome do paciente.\n",
    "\n",
    "No próximo passo, a função f = RecuperaDominioEmail será aplicada ao DynamicFrame \"nomeGeneralizado\". O resultado será um novo DynamicFrame chamado \"emailGeneralizado\" cuja coluna \"email\" conterá apenas o domínio do endereço de email.\n",
    "\n",
    "Na sequência, a função f = GeneralizaCep será aplicada ao DynamicFrame \"emailGeneralizado\". O resultado será um novo DynamicFrame chamado \"cepGeneralizado\" cuja coluna \"cep\" conterá apenas os 5 primeiros dígitos do CEP.\n",
    "\n",
    "Finalmente, a função f = AnoNascimento será aplicada ao DynamicFrame \"cepGeneralizado\". O resultado será um novo DynamicFrame chamado \"anoNascimento\" cuja coluna \"nascimento\" conterá apenas o ano da data de nascimento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecuperaUltimoSobrenome(rec):\n",
    "    nomeCompleto = rec[\"nome\"]\n",
    "    nomeSeparado = nomeCompleto.split()\n",
    "    rec[\"nome\"] = nomeSeparado[len(nomeSeparado)-1]\n",
    "    return rec\n",
    "\n",
    "nomeGeneralizado = Map.apply(frame = supressao, \n",
    "                             f = RecuperaUltimoSobrenome)\n",
    "\n",
    "nomeGeneralizado.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecuperaDominioEmail(rec):\n",
    "    emailCompleto = rec[\"email\"]\n",
    "    dominioEmail = emailCompleto.split(\"@\")\n",
    "    rec[\"email\"] = dominioEmail[1]\n",
    "    return rec\n",
    "\n",
    "emailGeneralizado = Map.apply(frame = nomeGeneralizado, \n",
    "                              f = RecuperaDominioEmail)\n",
    "\n",
    "emailGeneralizado.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então, vamos suprimir dia e mês do campo \"nascimento\", deixando apenas o ano de nascimento da pessoa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneralizaCep(rec):\n",
    "    cepOriginal = rec[\"cep\"]\n",
    "    rec[\"cep\"] = cepOriginal[0:5]\n",
    "    return rec\n",
    "\n",
    "cepGeneralizado = Map.apply(frame = emailGeneralizado, \n",
    "                            f = GeneralizaCep)\n",
    "\n",
    "cepGeneralizado.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnoNascimento(rec):\n",
    "    nascimentoOriginal = rec[\"nascimento\"]\n",
    "    anoNascimento = nascimentoOriginal.split(\"/\")\n",
    "    rec[\"nascimento\"] = anoNascimento[2]\n",
    "    return rec\n",
    "\n",
    "anoNascimento = Map.apply(frame = cepGeneralizado, \n",
    "                          f = AnoNascimento)\n",
    "\n",
    "anoNascimento.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomização/Perturbação/Ruído\n",
    "\n",
    "Voltamos a usar o transformador Map para a operação de perturbação. A coluna a ser perturbada é \"peso\", com base na função f = AddRuidoPeso, que arredondará o peso para o valor mais próximo da base 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Round(x, base=5):\n",
    "    return base * round(x/base)\n",
    "\n",
    "def AddRuidoPeso(rec):\n",
    "    pesoOriginal = rec[\"peso\"]\n",
    "    rec[\"peso\"] = Round(pesoOriginal)\n",
    "    return rec\n",
    "\n",
    "pesoArredondado = Map.apply(frame = anoNascimento, \n",
    "                            f = AddRuidoPeso)\n",
    "\n",
    "pesoArredondado.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashing\n",
    "\n",
    "O último passo será aplicar a função f = HashCPF no campo \"cpf\" também por meio do transformador Map. Para tanto, é necessária a importação das bibliotecas random (https://docs.python.org/3/library/random.html) e hashlib (https://docs.python.org/3/library/hashlib.html) do Python para posterior uso de suas funções randrange e sha256, respectivamente.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def HashCPF(rec):\n",
    "    cpfOriginal = str(rec[\"cpf\"]) + str(random.randrange(100,999))\n",
    "    rec[\"cpf\"] = hashlib.sha256(cpfOriginal.encode()).hexdigest()\n",
    "    return rec\n",
    "\n",
    "\n",
    "cpfHasheado = Map.apply(frame = pesoArredondado, \n",
    "                        f = HashCPF)\n",
    "\n",
    "cpfHasheado.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escreve o arquivo anonimizado em formato parquet no S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a execução de todos os passos acima, finalizamos com um DynamicFrame totalmente anonimizado. Seu conteúdo então poderá ser salvo em um novo bucket no Amazon S3 (https://aws.amazon.com/s3/), o qual poderá ser consumido pelo seu time de cientistas de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## @args: [connection_type = \"s3\", connection_options = {\"path\": s3_output_path}, format = \"parquet\"]\n",
    "## @inputs: [frame = cpfHasheado]\n",
    "\n",
    "glueContext.write_dynamic_frame.from_options(frame = cpfHasheado, \n",
    "                                             connection_type = \"s3\", \n",
    "                                             connection_options = {\"path\": s3_output_path},\n",
    "                                             format = \"parquet\")\n",
    "job.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}